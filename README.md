# Evaluating Small vs. Large Language Models in Task-Specific Multi-Turn Conversations: Challenges and Improvement Strategies

This project explores the performance of small vs. large language models (LLMs) in task-specific multi-turn conversations using two custom-built bots: a Job Search Bot and a Credit Card Assistant Bot. The analysis highlights issues in tool call accuracy, contextual understanding, and constraint adherence in small LLMs. Based on insights from relevant research papers, the report proposes strategies like fine-tuning with synthetic data, modular multi-LLM architecture, and ReAct-style prompting to improve small LLM performance in real-world applications.
